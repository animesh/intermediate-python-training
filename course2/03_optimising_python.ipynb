{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3 - Optimizing Python \n",
    "----------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "# Table of Content <a id='toc'></a>\n",
    "\n",
    "0. [meet the code](#0)\n",
    "\n",
    "1. [measuring](#1)\n",
    "\n",
    "    1.1. [timing](#2)\n",
    " \n",
    "    1.2. [measuring RAM usage](#3)\n",
    "\n",
    "\n",
    "2. [optimize](#4)\n",
    "\n",
    "   2.1. [Cython](#5)\n",
    "   \n",
    "   2.2. [Numba](#6)\n",
    "\n",
    "\n",
    "3. [Working with processes/threads](#7)\n",
    "\n",
    "   3.1 [Multiprocessing (and refactoring)](#8)\n",
    "\n",
    "   3.2. [numba and parallelization](#9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# 0. Meet the code <a id='0'></a>\n",
    "----------------------------------------------------------\n",
    "\n",
    "In this notebook we will mostly focus on a simple function which computes pairwise distance between a set of vectors, a very classical operation present in many data analysis methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(X):\n",
    "\n",
    "    num_vectors = len(X)\n",
    "    num_measurements = len(X[0])\n",
    "    D = [[0]*num_vectors for x in range(num_vectors)]\n",
    "    \n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "            d = []\n",
    "            for k in range(num_measurements):\n",
    "                d.append( ( X[i][k] - X[j][k] )**2 )\n",
    "            \n",
    "            D[i][j] = sum(d) **0.5\n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# 1. Measuring time and memory usage <a id='1'></a>\n",
    "----------------------------------------------------------\n",
    "\n",
    "The first step of any code optimization process should be measuring what your code is doing, in order to pinpoint where your effort should be focused.\n",
    "\n",
    "Here is an example function which computes pairwise Euclidian distances between multiple vectors values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "## let's generate some random data to play with : 200x100 matrix\n",
    "num_vector = 200\n",
    "num_measures = 100\n",
    "\n",
    "data = np.random.uniform(size=(num_vector,num_measures))\n",
    "print(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "## 1.1. Measuring time usage <a id='2'></a>\n",
    "\n",
    "On you terminal, you may measure up the taime taken by a python script execution using:\n",
    "\n",
    "`time python myscript.py`\n",
    "\n",
    "Or, using jupyter/ipython magic :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time D = pairwise_distance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "## applies on the whole cell\n",
    "\n",
    "D = pairwise_distance(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all nice, but there is always a bit a variability, which becomes very apparent on smaller time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smaller data set\n",
    "num_vector = 100\n",
    "num_measures = 10\n",
    "\n",
    "data = np.random.uniform(size=(num_vector,num_measures))\n",
    "\n",
    "%time D = pairwise_distance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, we have `timeit`:\n",
    "\n",
    "`python -m timeit myScript.py`\n",
    "\n",
    "Or :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit D = pairwise_distance(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can specify the number of runs and loops performed\n",
    "%timeit -n 2 -r 10 D = pairwise_distance(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performs `-r` runs, each time taking the best execution time out of `-n` loops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, already this is nice, we will definitely be using this to compare together different implementations.\n",
    "\n",
    "For example, I have rewritten the function using numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pairwise_distance_numpy(X):\n",
    "\n",
    "    num_vectors = X.shape[0]\n",
    "    num_measurements = X.shape[1] \n",
    "    D = np.empty((num_vectors, num_vectors), dtype=np.float64)\n",
    "    \n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "            d = np.square( np.subtract(X[i], X[j]) )\n",
    "            D[i, j] = np.sqrt(np.sum(d))\n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100x100 data set\n",
    "num_vector = 100\n",
    "num_measures = 100\n",
    "\n",
    "data = np.random.uniform(size=(num_vector,num_measures))\n",
    "\n",
    "print('native:')\n",
    "%timeit -n 5 -r 3 D = pairwise_distance(data)\n",
    "print('numpy:')\n",
    "%timeit -n 5 -r 3 D = pairwise_distance_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! \n",
    "\n",
    "<br> \n",
    "\n",
    "However, most of the time your code is more complex than a single function, and before optimizing you first want to see which function you should optimize. That is when **profiling** comes in handy.\n",
    "\n",
    "Imagine you have a script, implementing a Kmeans algorithm. \n",
    "Here are the functions which look like the best candidates for optimization :\n",
    "* `computeDistanceToCentroid` : compute the distance between a poitnand a centroid\n",
    "* `computeNearestCentroid` : compute which centroid is the closest to each point (actualy calls `computeDistanceToCentroid`, but also possess some other potentially costly computations)\n",
    "* `computeCentroids` : computes the position of the centroid of a points with a given cluster assignment\n",
    "\n",
    "Are they really the best candidate ? which one shuld we go for first ?\n",
    "\n",
    "We recommend [cProfile](https://docs.python.org/3/library/profile.html)\n",
    "\n",
    "in the terminal :\n",
    "\n",
    "```\n",
    "python -m cProfile -o profile.log -s cumtime myScript.py\n",
    "```\n",
    "\n",
    "will execute the script, and profile time usage of every functions\n",
    " * `-o` : output file for the profiling log\n",
    " * `-s cumtime` : to sort by cumulative time spent in a single function\n",
    "\n",
    "in jupyter :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating some random data \n",
    "def generateCluster( n , means , sds ):\n",
    "    P = np.random.randn( len(means) , n )\n",
    "    for i in range(len(means)):\n",
    "        P[i,] = P[i,] * sds[i] + means[i]\n",
    "    \n",
    "    return P\n",
    "\n",
    "\n",
    "clusterSizes = [4000,2000,4000,4000,2000 ]\n",
    "clusterMeans = [ [ 0 , -2 ] , [ 3 , 3 ] ,[ -1 , 3 ], [-5, 0] , [5,-1] ]\n",
    "clusterSDs = [ [0.5,1] ,[1,0.5] ,[0.5,0.5],[2,1] ,[1,1] ]\n",
    "C = []\n",
    "A = []\n",
    "for i in range( len(clusterSizes) ):\n",
    "    C.append( generateCluster( clusterSizes[i] , clusterMeans[i] , clusterSDs[i] ) )\n",
    "    A += [i]*clusterSizes[i]\n",
    "Points = np.concatenate( C , axis=1)\n",
    "realAssignment = np.array(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Kmeans import Kmeans\n",
    "# performing Kmean\n",
    "k=5\n",
    "%prun -l 30 -s cumtime  kmeanAssignment = Kmeans( Points , k , maxNbRounds=1000 ) \n",
    "# the %prun magic command activate profiling\n",
    "#  -l 30 : limits the report to 30 lines\n",
    "#  -s cumtime : sort by decreasing cumtime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns correspond to:\n",
    " * ncalls : for the number of calls.\n",
    " * tottime : for the total time spent in the given function (and excluding time made in calls to sub-functions)\n",
    " * percall : is the quotient of tottime divided by ncalls\n",
    " * cumtime : is the cumulative time spent in this and all subfunctions (from invocation till exit). This figure is accurate even for recursive functions.\n",
    " * percall : is the quotient of cumtime divided by primitive calls\n",
    "\n",
    "\n",
    "### Micro-Exercise:\n",
    "* Look at the profile. Where should optimization efforts go first ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "## 1.2. measuring RAM usage <a id='3'></a>\n",
    "\n",
    "Sometimes, you also want to measure the memory imprint of your code \n",
    "\n",
    "The nicest tool I know about for that is [memory-profiler](https://pypi.org/project/memory-profiler/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install it with :\n",
    "\n",
    "```python\n",
    "!pip install memory_profiler\n",
    "```\n",
    "\n",
    "Basically, in your code you add a **decorator** to the function of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory_profiler import profile\n",
    "\n",
    "@profile\n",
    "def my_func():\n",
    "    a = [1] * (10 ** 6)\n",
    "    b = [2] * (2 * 10 ** 7)\n",
    "    del b\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you may either do it command-line style  :\n",
    "\n",
    "```\n",
    "python -m memory_profiler example.py\n",
    "```\n",
    "\n",
    "or prefer jupyter-magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gives us a result: `peak memory: 210.19 MiB, increment: 152.58 MiB`\n",
    "            \n",
    "But it does not like that our code is in the same notebook. Let's have it in another script :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import my_func\n",
    "\n",
    "%memit my_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that is quite nice : we have a run down of the RAM usage, line-by-line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Micro-Exercise:\n",
    "* profile the memory usage of `pairwise_distance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "# 2. Code optimization <a id='4'></a>\n",
    "---------------------------------\n",
    "\n",
    "Now that we have seen the tools to measure our code resource usage, we will review a couple of tricks that can help you speedup your python code tremendously.\n",
    "\n",
    "The firsts are basic:\n",
    " 1. **apply standard good-sense** : does your code reads/write to the disk more than it need to ? Do you spend a lot of time searching for items in lists instead of dictionnaries ?\n",
    " 2. **switch to numpy** : vectorized operations are great (as we have seen). \n",
    " \n",
    "> don't know how to numpy? You can [get started here](https://numpy.org/doc/stable/user/quickstart.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's generate a toy dataset of random number vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vector = 200\n",
    "num_measures = 100\n",
    "\n",
    "data = np.random.uniform(size=(num_vector,num_measures))\n",
    "print(type(data[0][0]))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pure Python (and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit result = pairwise_distance_numpy(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "## 2.1. Cython <a id='5'></a>\n",
    "\n",
    "**[Cython](https://cython.org/)** provides way to transform a python code into C compiled code failry seamlessly.\n",
    "\n",
    "By default, Cython retains Python flexibility by creating the ugliest of C-codes. This comes at the cost of a lot of efficiency, but already it is enough to speed your code some.\n",
    "\n",
    "The \"command-line\" flavor of cython involves either calling `cython` or writing a little `setup.py` file for your code. It is a bit of work at the start but actually quite easy once you have done it a couple of time : see [here for examples](https://cython.readthedocs.io/en/latest/src/quickstart/build.html)\n",
    "\n",
    "The jupyter way :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pure python \n",
    "def f_native(x):\n",
    "    return x ** 2 - x\n",
    "\n",
    "\n",
    "def integrate_f_native(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f_native(a + i * dx)\n",
    "    return s * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "## cython, without changing a single thing\n",
    "\n",
    "def f(x):\n",
    "    return x ** 2 - x\n",
    "\n",
    "\n",
    "def integrate_f(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f(a + i * dx)\n",
    "    return s * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"native\")\n",
    "%timeit -n 3 -r 5 result = integrate_f_native(0,1,1000000)\n",
    "print(\"simple cython\")\n",
    "%timeit -n 3 -r 5 result = integrate_f(0,1,1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so a speedup of about a third, fairly nice for a single line change.\n",
    "\n",
    "But, let's look how Cython performed with our code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "## cython, without changing a single thing\n",
    "\n",
    "def f(x):\n",
    "    return x ** 2 - x\n",
    "\n",
    "\n",
    "def integrate_f(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f(a + i * dx)\n",
    "    return s * dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can give some hints to Cython, to help it compile the code better :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "## cython, typing \n",
    "\n",
    "def f_typed( double x ):\n",
    "    return x ** 2 - x\n",
    "\n",
    "\n",
    "def integrate_f_typed( double a, double b, int N):\n",
    "    cdef int i\n",
    "    cdef double s, dx\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f_typed(a + i * dx)\n",
    "    return s * dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"native\")\n",
    "%timeit -r 5 -n 3 result = integrate_f_native(0,1,1000000)\n",
    "print(\"cython - simple\")\n",
    "%timeit -r 5 -n 3 result = integrate_f(0,1,1000000)\n",
    "print(\"cython - some typing\")\n",
    "%timeit -r 5 -n 3 result = integrate_f_typed(0,1,1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! that's more like it.\n",
    "\n",
    "Of course, there is more things we could do, like typing the return type of the functions and so on, as shown in this [quickstart tutorial](https://cython.readthedocs.io/en/latest/src/quickstart/cythonize.html) (which this example is grabbed from). \n",
    "\n",
    "<br>\n",
    "\n",
    "These compiling tools usually won't work with external libraries, but a cool thing about Cython is that it works very well with numpy structures.\n",
    "\n",
    "So le'ts see what we can get with our `pairwise_distance`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython --annotate\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "def pairwise_distance_cython(double[:, ::1] X):\n",
    "    \n",
    "    cdef int num_vectors = X.shape[0]\n",
    "    cdef int num_measurements = X.shape[1]\n",
    "    cdef double d\n",
    "    cdef double[:, ::1] D = np.empty((num_vectors, num_vectors))\n",
    "    \n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "            d=0\n",
    "            for k in range(num_measurements):\n",
    "                d += ( X[i][k] - X[j][k] )**2\n",
    "\n",
    "            D[i, j] = d**0.5\n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print('numpy:')\n",
    "%timeit -n 3 -r 5 D = pairwise_distance_numpy(data)\n",
    "print('cython:')\n",
    "%timeit -n 3 -r 5 result = pairwise_distance_cython(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so now we have really gotten down.\n",
    "\n",
    "So cython is really great, although it does take some practice to get it to work the way you want. \n",
    "They do have a [nice tutorial](https://cython.readthedocs.io/en/latest/index.html) though.\n",
    "\n",
    "> note : cython is also a great way to interface python and C code.\n",
    "\n",
    "> it is also fairly easy to do [profiling on cython code](https://cython.readthedocs.io/en/latest/src/tutorial/profiling_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "\n",
    "## 2.3. Numba <a id='6'></a>\n",
    "\n",
    "**[Numba](https://numba.pydata.org/)** is an interesting alternative to Cython. It provide a number of optimization routines for python code, the most well know being **`@jit`** for **just-in-time** compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unchanged code \n",
    "\n",
    "@jit\n",
    "def pairwise_distance_numba(X):\n",
    "\n",
    "    num_vectors = X.shape[0]\n",
    "    num_measurements = X.shape[1] \n",
    "    D = np.empty((num_vectors, num_vectors), dtype=np.float64)\n",
    "    \n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "            d = 0.\n",
    "            for k in range(num_measurements):\n",
    "                d += np.square( np.subtract(X[i][k], X[j][k])  )\n",
    "            D[i, j] = np.sqrt(d)\n",
    "    return(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time result = pairwise_distance_numba(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> the first time it is executed the function is compiled. Run the function again to get the execution time without compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 5 -r 3 result = pairwise_distance_numba(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Woosh!** results similar to Cython, but without all the hard work of typing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative syntax\n",
    "import numba\n",
    "pairwise_distance_numba = numba.jit(pairwise_distance_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is pretty bluffing, but sometimes it can be a bit difficult to get this level of performance.\n",
    "\n",
    "Most external libraries are missing from numba, and [not all of numpy's code has been ported as well](https://numba.pydata.org/numba-doc/dev/reference/numpysupported.html).\n",
    "\n",
    "> Note : a lot of function in external libraries (such as the ones of sklearn) have already been optimized and compiled, so there would not necessarily be much to gain there anyway...\n",
    "\n",
    "All-in-all, it depends quite a lot on the particulars of what you want to optimize : [here are some tips](https://numba.pydata.org/numba-doc/latest/user/performance-tips.html)\n",
    "\n",
    "\n",
    "> there also exists ways to [compile numba code ahead of time](https://numba.pydata.org/numba-doc/dev/user/pycc.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Comparison with replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 10 result = pairwise_distance_numpy(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 10 result = pairwise_distance_cython(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 10 result = pairwise_distance_numba(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is an example which tends to favors optimization by numba. In some other cases Cython may perform better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "\n",
    "# 3. Working with processes/threads <a id='7'></a>\n",
    "------------------------------------------------------\n",
    "\n",
    "## 3.1 Multiprocessing (and refactoring) <a id='8'></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of multiple cores using the `multiprocessing` module. \n",
    "\n",
    "In this approach, separate __processes__ are used, __not threads__. \n",
    "\n",
    "The use of threads is generally blocked by Python because of the *\"Global Interpreter Lock\"*. This was a necessary design feature as a trade-off for the enormous flexibility in memory management that Python makes possible. This means that there is no shared memory when using multiprocessing, and thus the individual tasks must be independent.\n",
    "\n",
    "`multiprocessing` generally works well with lists, where one maps a function to each element of the list and these operations are computed as separated processes on separate cores per element of the list. To do this, we'll need to refactor our silly distance function. One approach would be to populate a list containing each of the vector pairs. The drawback here is the memory overhead of this list object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_list(X):\n",
    "\n",
    "    list_of_tuples = list()\n",
    "    \n",
    "    num_vectors = X.shape[0]\n",
    "    num_measurements = X.shape[1] \n",
    "    \n",
    "    for i in range(num_vectors):\n",
    "        for j in range(num_vectors):\n",
    "            list_of_tuples.append((X[i],X[j]))\n",
    "            \n",
    "    return list_of_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tuples = pairwise_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tuples[0] #instpect 1st element"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll need to refactor our function for computing distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_rf(X):\n",
    "    \n",
    "    assert(len(X) == 2)\n",
    "    assert(len(X[0]) == len(X[1]))\n",
    "    \n",
    "    d=0.\n",
    "    for k in range(len(X[1])):\n",
    "        d += np.square( np.subtract(X[0][k], X[1][k]))\n",
    "    \n",
    "    return( np.sqrt(np.sum(d) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 3  result = list(map(pairwise_distance_rf,  list_of_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are down to native python performance...\n",
    "\n",
    "Let's now repreat this with multiprocessing : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use the with statement to be sure we do not forget to do a pool.close() \n",
    "with mp.Pool(2) as pool :\n",
    "    %timeit -n 1 -r 3  result = pool.map(pairwise_distance_rf, list_of_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! So far : **2 process ~ 1.5-2  x speedup**\n",
    "\n",
    "Let's see if that holds up :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for NP in [1,2,4,8]:\n",
    "    print(NP)\n",
    "    with mp.Pool(NP) as pool :\n",
    "        %timeit -n 1 -r 3  result = pool.map(pairwise_distance_rf, list_of_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what we see is fairly classical : we get diminishing return with each new process because of the overhead of multiprocessing. \n",
    "Still, the alternative was to let most of you CPU idle..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, `multiprocessing` does not always lead to speedups as it may prevent numpy from doing some of its optimization tricks, such as vectorization.\n",
    "\n",
    "For instance, let's see how `multiprocessing` work on the vectorized version of our function :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance_rf_2(X):\n",
    "    \n",
    "    assert(len(X) == 2)\n",
    "    assert(len(X[0]) == len(X[1]))\n",
    "    \n",
    "    d = np.square( np.subtract(X[0], X[1]))\n",
    "    \n",
    "    return( np.sqrt(np.sum(d) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.uniform(size=(200,100)) # I make the data a bit larger\n",
    "list_of_tuples = pairwise_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit -n 1 -r 3  result = list(map(pairwise_distance_rf_2, list_of_tuples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are back to numpy performance levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for NP in [1,2,4,8]:\n",
    "    print(NP)\n",
    "    with mp.Pool(NP) as pool :\n",
    "        %timeit -n 1 -r 3  result = pool.map(pairwise_distance_rf_2, list_of_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... no tremendous performance gains ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "[back to the toc](#toc)\n",
    "\n",
    "\n",
    "## 3.2. numba and parallelization  <a id='9'></a>\n",
    "\n",
    "It is possible to provide a `numba` function to `mp.pool`, but `numba` already provides what's necessary to parallelize your code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "# njit -> no-python jit\n",
    "\n",
    "@njit(parallel=True)\n",
    "def pairwise_distance_numba_prange(X):\n",
    "\n",
    "    num_vectors = X.shape[0]\n",
    "    num_measurements = X.shape[1] \n",
    "    D = np.empty((num_vectors, num_vectors), dtype=np.float64)\n",
    "    \n",
    "    for i in prange(num_vectors): # note usage of prange\n",
    "        for j in range(num_vectors):\n",
    "            d = 0.\n",
    "            for k in range(num_measurements):\n",
    "                d += np.square( np.subtract(X[i][k], X[j][k])  )\n",
    "            D[i, j] = np.sqrt(d)\n",
    "    return(D)\n",
    "\n",
    "toydata = np.random.uniform(size=(10,10)) # I make toy data to launch the function once and compile it\n",
    "toyresult = pairwise_distance_numba_prange( toydata ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No numba, vectorized\")\n",
    "%timeit -n 1 -r 3  result = list(map(pairwise_distance_rf_2, list_of_tuples))\n",
    "print(\"numba\")\n",
    "%timeit -n 1 -r 3 result = pairwise_distance_numba( data )\n",
    "print(\"numba parallel=True\")\n",
    "%timeit -n 1 -r 3 result = pairwise_distance_numba_prange( data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant improvement with Numba again, but clearly Numba really shines when working with nested loops.\n",
    "\n",
    "\n",
    "> cython also has ways to do some openMP in its compiled code.\n",
    "\n",
    "**In the end** which of these different method you should use will depend on the particulars of the computations you have to make."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
